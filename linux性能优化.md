# linux性能优化



![img](https://static001.geekbang.org/resource/image/9e/7a/9ee6c1c5d88b0468af1a3280865a6b7a.png)



![img](https://static001.geekbang.org/resource/image/0f/ba/0faf56cd9521e665f739b03dd04470ba.png)

## CPU性能篇

### 到底应该怎么理解平均负载？

```
13:11  up 124 days, 3 users, load averages: 1.99 2.10 2.33
当前时间  系统登录时长  登录账户个数  1、5、15分钟CPU的平均负载
```

##### 平均负载

指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系

* 可运行状态的进程：正在使用 CPU 或者正在等待 CPU 的进程，ps 命令看到的处于 R 状态（Running 或 Runnable）的进程
* 不可中断状态的进程：正处于内核态关键流程中的进程，不可被打断，比如最常见的是等待硬件设备的 I/O 响应， ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程，不可中断状态实际上是系统对进程和硬件设备的一种保护机制

最理想的是每个 CPU 上都刚好运行着一个进程，每个 CPU 都得到充分利用。当平均负载为 2 时，意味着：

* 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用
* 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲
* 在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU

##### 平均负载为多少时合理

查看本机CPU数量：

```
grep 'model name' /proc/cpuinfo | wc -l
4
```

1、5、15分钟的平均负载，提供了分析系统负载趋势的数据来源，可以更全面、更立体地理解目前的负载状况，当平均负载高于 CPU 数量 70% 的时候，你就应该分析排查负载高的问题了

##### 平均负载与 CPU 使用率

平均负载不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：

* CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时两者是一致的
* I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高
* 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高

##### 案例分析

```
apt install stress sysstat
```

* stress：一个 Linux 系统压力测试工具，用作异常进程模拟平均负载升高的场景

* sysstat：包含了常用的 Linux 性能工具，用来监控和分析系统的性能。这个包的两个命令 mpstat 和 pidstat
  * mpstat：一个常用的多核 CPU 性能分析工具，可实时查看每个 CPU 的性能指标以及所有 CPU 的平均指标
  * pidstat：一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标

场景一：CPU  密集型进程

```
// 第一个终端运行  stress  命令，模拟一个  CPU  使用率 100% 的场景
stress --cpu 1 --timeout 600

// 第二个终端运行 uptime 查看平均负载的变化情况
// -d 参数表示高亮显示变化的区域
watch -d uptime

// 第三个终端运行 mpstat 查看  CPU  使用率的变化情况
// -P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据
mpstat -P ALL 5

平均负载的升高正是由于 CPU 使用率为 100% 

// 哪个进程导致了 CPU 使用率为 100% ？可以使用 pidstat 来查询
// 间隔5秒后输出一组数据
pidstat -u 5 1
```

场景二：I/O  密集型进程

```
// 第一个终端运行  stress  命令，但这次模拟  I/O  压力，即不停地执行  sync
stress -i 1 --timeout 600

// 第二个终端运行 uptime 查看平均负载的变化情况
watch -d uptime

// 第三个终端运行 mpstat 查看  CPU  使用率的变化情况
mpstat -P ALL 5

平均负载的升高正是由于 IO 使用率为 90% 

// 哪个进程导致了 IO 使用率为 90% ？可以使用 pidstat 来查询
pidstat -u 5 1
```

场景三：大量进程的场景

```
// 第一个终端运行  stress  命令，模拟创建了16个进程
stress -c 16 --timeout 600
 
// 第二个终端运行 uptime 查看平均负载的变化情况， 系统只有 4 个 CPU，明显比 16 个进程要少得多，因而，系统的 CPU 处于严重过载状态
watch -d uptime

// 第三个终端查看哪个进程占用资源，发现有16个进程分布在4个CPU上
pidstat -u 5 1
```

### 经常说的 CPU 上下文切换是什么意思？

##### CPU 上下文

用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文

##### CPU 上下文切换

先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。根据任务的不同，CPU 的上下文切换可以分为几个不同的场景，进程上下文切换、线程上下文切换以及中断上下文切换

##### 进程上下文切换

从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，调用 read() 读取文件内容，调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。一次系统调用的过程，其实是发生了两次 CPU 上下文切换。

* 进程上下文切换：从一个进程切换到另一个进程运行，进程的切换只能发生在内核态，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间，这个时间相当可观
* 系统调用：一直是同一个进程在运行。通常称为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的

进程切换时才需要切换上下文，进程切换的原因：

* CPU时间片到了
* 系统资源不足导致进程被挂起
* 通过睡眠函数  sleep 这样的方法将自己主动挂起时
* 有优先级更高的进程运行时
* 发生硬件中断时

##### 线程上下文切换

线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源

* 当进程只有一个线程时，可以认为进程就等于线程
* 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的
* 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的

线程的上下文切换其实就可以分为两种情况：

* 第一种： 前后两个线程属于不同进程。因为资源不共享，所以切换过程就跟进程上下文切换是一样
* 第二种：前后两个线程属于同一个进程。因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据

虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源

##### 中断上下文切换

中断处理会打断进程的正常调度和执行，转而调用中断处理程序。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。跟进程上下文不同，中断上下文切换并不涉及到进程的用户态，所以无需保存其用户态资源，只需要保存内核态中断服务程序执行所必需的状态。对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。大部分中断处理程序都短小精悍，以便尽可能快的执行结束。跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能

* CPU 上下文切换，是保证 Linux 系统正常工作的核心功能之一，一般情况下不需要特别关注
* 过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降

##### 查看系统的上下文切换情况

vmstat：一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数

```
// 每隔5秒输出1组数据
vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 7005360  91564 818900    0    0     0     0   25   33  0  0 100  0  0
 
r（running or runnable）：就绪队列的长度，也就是正在运行和等待 CPU 的进程数
b（blocked）：处于不可中断睡眠状态的进程数
in (interrupt)：每秒中断的次数
cs (context switch)：每秒上下文切换的次数
us (user CPU time)：用户空间占用CPU百分比
sy (system CPU time)：内核空间占用CPU百分比
ni (nice CPU time)：用户进程空间内改变过优先级的进程占用CPU百分比
id (idle)：空闲CPU百分比
wa (iowait)：等待输入输出的CPU时间百分比
hi (hardware irq)：硬件中断
si (software irq)：软件中断 
st (steal time)：实时
```

查看每个进程的详细情况，需要使用 pidstat。加上 -w 选项，就可以查看每个进程上下文切换的情况

```
// 每隔5秒输出1组数据
pidstat -w 5
Linux 4.15.0 (ubuntu)  09/23/18  _x86_64_  (2 CPU)

08:18:26      UID       PID   cswch/s nvcswch/s  Command
08:18:31        0         1      0.20      0.00  systemd
08:18:31        0         8      5.40      0.00  rcu_sched

cswch（voluntary context switches）：自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时
nvcswch（non voluntary context switches）：非自愿上下文切换，是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时
```

##### 案例分析

sysbench 是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况

```
// 空闲系统的上下文切换次数，间隔1秒后输出1组数据
vmstat 1 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 6984064  92668 830896    0    0     2    19   19   35  1  0 99  0  0
 
// 第一个终端里运行 sysbench 模拟系统多线程调度的瓶颈, 以10个线程运行5分钟的基准测试，模拟多线程切换的问题
sysbench --threads=10 --max-time=300 threads run

// 第二个终端运行 vmstat，观察上下文切换情况, 每隔1秒输出1组数据（需要Ctrl+C才结束）
vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 6487428 118240 1292772    0    0     0     0 9019 1398830 16 84  0  0  0
 8  0      0 6487428 118240 1292772    0    0     0     0 10191 1392312 16 84  0  0  0

r 列：就绪队列的长度已经到了 8，远远超过了系统 CPU 的个数 2，所以肯定会有大量的 CPU 竞争
us（user）和 sy（system）列：系统 CPU 使用率，也就是 sy 列高达 84%，说明 CPU 主要是被内核占用了
in  列：中断次数也上升到了 1 万左右，说明中断处理也是个潜在的问题

// 第三个终端再用 pidstat 来看一下， CPU 和进程上下文切换的情况
// 每隔1秒输出1组数据（需要 Ctrl+C 才结束）-w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标$ pidstat -w -u 1
CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 100%。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat  ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd

// pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标,-wt 参数表示输出线程的上下文切换指标
pidstat -wt 1
虽然 sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多

// 第三个终端里，  Ctrl+C 停止刚才的 pidstat 命令，然后运行下面的命令，观察中断的变化情况
watch -d cat /proc/interrupts
变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI），这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的
```

如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。这时，还需要根据上下文切换的类型，再做具体分析：

* 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题
* 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈
* 中断次数变多了，说明 CPU 被中断处理程序占用，需要查看 /proc/interrupts 文件来分析具体的中断类型

### 某个应用的CPU使用率居然达到100%，我该怎么办？

##### CPU 使用率

为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1

* 节拍率 HZ 是内核的可配选项，不同的系统可能设置不同数值，你可以通过查询 /boot/config 内核选项来查看它的配置值，用户空间程序并不能直接访问该变量

```
grep 'CONFIG_HZ=' /boot/config-$(uname -r)
CONFIG_HZ=250
```

* 为了方便用户空间程序，内核还提供了一个用户空间节拍率 USER_HZ，它总是固定为 100，也就是 1/100 秒

Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat 提供的就是系统的 CPU 和任务统计信息

```
// 只保留各个CPU的数据
cat /proc/stat | grep ^cpu
cpu  280580 7407 286084 172900810 83602 0 583 0 0 0
cpu0 144745 4181 176701 86423902 52076 0 301 0 0 0
cpu1 135834 3226 109383 86476907 31525 0 282 0 0 0

每一列的数值含义：
user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间
nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低
system（通常缩写为 sys），代表内核态 CPU 时间
idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）
iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间
irq（通常缩写为 hi），代表处理硬中断的 CPU 时间
softirq（通常缩写为 si），代表处理软中断的 CPU 时间
steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间
guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间
```

CPU 使用率：除了空闲时间外的其他时间占总 CPU 时间的百分比，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率

Linux 给每个进程提供了运行情况的统计信息， /proc/[pid]/stat。这个文件包含的数据总共有 52 列的数据

对比一下 top 和 ps 这两个工具报告的 CPU 使用率，默认的结果很可能不一样，因为 top 默认使用 3 秒时间间隔，而 ps 使用的却是进程的整个生命周期

##### 怎么查看 CPU 使用率

* top：显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况

```
// 默认每3秒刷新一次
top
top - 11:58:59 up 9 days, 22:47,  1 user,  load average: 0.03, 0.02, 0.00
Tasks: 123 total,   1 running,  72 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  8169348 total,  5606884 free,   334640 used,  2227824 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  7497908 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    1 root      20   0   78088   9288   6696 S   0.0  0.1   0:16.83 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.05 kthreadd
    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:0H

第三行显示CPU使用率，默认显示所有 CPU 平均值，按下数字 1 ，就可以切换到每个 CPU 的使用率
%CPU 列，表示进程的 CPU 使用率。它是用户态和内核态 CPU 使用率的总和
如果要细分进程的用户态 CPU 和内核态 CPU，需要使用pidstat
// 每隔1秒输出一组数据，共输出5组
$ pidstat 1 5
15:56:02      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
15:56:03        0     15006    0.00    0.99    0.00    0.00    0.99     1  dockerd

用户态 CPU 使用率 （%usr）
内核态 CPU 使用率（%system）
运行虚拟机 CPU 使用率（%guest）
等待 CPU 使用率（%wait）
总的 CPU 使用率（%CPU）
```

* ps：只显示每个进程的资源使用情况

##### CPU 使用率过高怎么办？

通过 top、ps、pidstat 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程，但是无法定位是哪个函数，GDB 在调试程序错误方面很强大。但是并不适合在性能分析的早期应用。因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。适合在第一时间分析进程的 CPU 问题的是 perf

```
// perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数
perf top
Samples: 833  of event 'cpu-clock', Event count (approx.): 97742399
Overhead  Shared Object       Symbol
   7.28%  perf                [.] 0x00000000001f78a4
   4.72%  [kernel]            [k] vsnprintf
   4.32%  [kernel]            [k] module_get_kallsym
   3.65%  [kernel]            [k] _raw_spin_unlock_irqrestore
...

第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）
第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示
第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等
第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间
最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示

perf record 则提供了保存数据的功能，保存后的数据，需要用 perf report 解析展示，在实际使用中，会加上 -g 参数，开启调用关系的采样，方便根据调用链来分析性能问题
```

### 系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？





### 怎么理解Linux软中断？

中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。由于中断处理程序会打断其他进程的运行，所以，为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失

##### 软中断

为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段：

* 上半部：用来快速处理中断，在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。直接处理硬件请求，即硬中断，特点是快速执行，如键盘、鼠标的输入、硬盘的读取写入、网卡有数据

* 下半部：用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。由内核触发，即软中断，特点是延迟执行，如定时器、内核调度和 RCU 锁（Read-Copy Update 的缩写）

##### 查看软中断和内核线程

* /proc/softirqs 提供了软中断的运行情况
* /proc/interrupts 提供了硬中断的运行情况

```

cat /proc/softirqs
                    CPU0       CPU1
          HI:          0          0
       TIMER:     811613    1972736
      NET_TX:         49          7
      NET_RX:    1136736    1506885
       BLOCK:          0          0
    IRQ_POLL:          0          0
     TASKLET:     304787       3691
       SCHED:     689718    1897539
     HRTIMER:          0          0
         RCU:    1330771    1354737
```

软中断实际上是以内核线程的方式运行的，每个 CPU 都对应一个软中断内核线程，叫做  ksoftirqd/CPU 编号

```
ps aux | grep softirq
root         7  0.0  0.0      0     0 ?        S    Oct10   0:01 [ksoftirqd/0]
root        16  0.0  0.0      0     0 ?        S    Oct10   0:01 [ksoftirqd/1]
```

### 系统中出现大量不可中断进程和僵尸进程怎么办？

当碰到无法解释的 CPU 使用率问题时，先要检查一下是不是短时应用在捣鬼。短时应用的运行时间比较短，很难在 top 或者 ps 这类展示系统概要和进程快照的工具中发现，需要使用记录事件的工具来配合诊断，比如 execsnoop 或者 perf top

##### 进程状态

```
top
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
28961 root      20   0   43816   3148   4040 R   3.2  0.0   0:00.01 top
  620 root      20   0   37280  33676    908 D   0.3  0.4   0:00.01 app
    1 root      20   0  160072   9416   6752 S   0.0  0.1   0:37.64 systemd
 1896 root      20   0       0      0      0 Z   0.0  0.0   0:00.00 devapp
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.10 kthreadd
    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:0H
    6 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 mm_percpu_wq
    7 root      20   0       0      0      0 S   0.0  0.0   0:06.37 ksoftirqd/0
```

* R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行
* D 是 Disk Sleep 的缩写，不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断
* Z 是 Zombie 的缩写，表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源
* S 是 Interruptible Sleep 的缩写，可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态
* I 是 Idle 的缩写，空闲状态，用在不可中断睡眠的内核线程上。硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会
*  T 或者 t，Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）
*  X， Dead 的缩写，表示进程已经消亡，不会在 top 或者 ps 命令中看到它

如果系统或硬件发生了故障，进程可能会在不可中断状态保持很久，甚至导致系统中出现大量不可中断进程。这时，你就得注意下，系统是不是出现了 I/O 等性能问题。

正常情况下，当一个进程创建了子进程后，应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，父进程还可以注册 SIGCHLD 信号的处理函数，异步回收资源。如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免

##### 案例分析

```
ps aux | grep /app
root      4009  0.0  0.0   4376  1008 pts/0    Ss+  05:51   0:00 /app
root      4287  0.6  0.4  37280 33660 pts/0    D+   05:54   0:00 /app
root      4288  0.6  0.4  37280 33668 pts/0    D+   05:54   0:00 /app
s 表示这个进程是一个会话的领导进程，而 + 表示前台进程组
```

* 进程组：表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员
* 会话：指共享同一个控制终端的一个或多个进程组

```
// 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束
$ top
top - 05:56:23 up 17 days, 16:45,  2 users,  load average: 2.00, 1.68, 1.39
Tasks: 247 total,   1 running,  79 sleeping,   0 stopped, 115 zombie
%Cpu0  :  0.0 us,  0.7 sy,  0.0 ni, 38.9 id, 60.5 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  0.7 sy,  0.0 ni,  4.7 id, 94.6 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4340 root      20   0   44676   4048   3432 R   0.3  0.0   0:00.05 top
 4345 root      20   0   37280  33624    860 D   0.3  0.0   0:00.01 app
 4344 root      20   0   37280  33624    860 D   0.3  0.4   0:00.01 app
    1 root      20   0  160072   9416   6752 S   0.0  0.1   0:38.59 systemd
...

1. 第一行的平均负载（ Load Average），平均负载正在升高；而 1 分钟内的平均负载已经达到系统的 CPU 个数，说明系统很可能已经有了性能瓶颈
2. 第二行的 Tasks，僵尸进程比较多，而且还在不停增加，说明有子进程在退出时没被清理
3. 两个 CPU 的使用率情况，iowait 分别是 60.5% 和 94.6%，好像有点儿不正常
4. 最后再看每个进程的情况， CPU 使用率最高的进程只有 0.3%，看起来并不高；但有两个进程处于 D 状态，它们可能在等待 I/O，但光凭这里并不能确定是它们导致了 iowait 升高
```

