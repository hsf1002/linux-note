# RAM

### Linux内存是怎么工作的？

##### 内存映射

Linux 内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。这样进程就可以很方便地访问内存，更确切地说是访问虚拟内存。内存映射，就是将虚拟内存地址映射到物理内存地址。内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系

![img](https://static001.geekbang.org/resource/image/fc/b6/fcfbe2f8eb7c6090d82bf93ecdc1f0b6.png)

页表实际上存储在 CPU 的内存管理单元 MMU 中，这样，正常情况下，处理器就可以直接通过硬件，找出要访问的内存。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。另外，TLB（Translation Lookaside Buffer，转译后备缓冲器）会影响 CPU 的内存访问性能。TLB 其实就是 MMU 中页表的高速缓存。由于进程的虚拟地址空间是独立的，而 TLB 的访问速度又比 MMU 快得多，所以，通过减少进程的上下文切换，减少 TLB 的刷新次数，就可以提高 TLB 缓存的使用率，进而提高 CPU 的内存访问性能。

MMU 并不以字节为单位来管理内存，而是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。页的大小只有 4 KB ，导致整个页表会变得非常大。仅 32 位系统就需要 100 多万个页表项（4GB/4KB），才可以实现整个地址空间的映射。为了解决页表项过多的问题，Linux 提供了两种机制

![img](https://static001.geekbang.org/resource/image/b5/25/b5c9179ac64eb5c7ca26448065728325.png)

* 多级页表：Linux 用的正是四级页表来管理内存页，如图所示，虚拟地址被分为 5 个部分，前 4 个表项用于选择页，而最后一个索引表示页内偏移
* 大页（HugePage）：就是比普通页更大的内存块，常见的大小有 2MB 和 1GB。大页通常用在使用大量内存的进程上，比如 Oracle、DPDK 等

##### 虚拟内存空间分布

![img](https://static001.geekbang.org/resource/image/71/5d/71a754523386cc75f4456a5eabc93c5d.png)

* 只读段：包括代码和常量等
* 数据段：包括全局变量等
* 堆：包括动态分配的内存，从低地址开始向上增长
* 文件映射段：包括动态库、共享内存等，从高地址开始向下增长
* 栈：包括局部变量和函数调用的上下文等，栈的大小是固定的，一般是 8 MB

堆和文件映射段的内存是动态分配的，如 C 标准库的 malloc() 或者 mmap() 

##### 内存分配与回收

malloc() 是 C 标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 brk() 和 mmap()

* brk：小块内存（小于 128K），C 标准库使用 brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。可以减少缺页异常的发生，提高内存访问效率。由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片。由于brk分配的内存是推_edata指针，从堆的低地址向高地址推进。这种情况下，如果高地址的内存不释放，低地址的内存是得不到释放的
* mmap：大块内存（大于 128K），则直接使用内存映射 mmap() 来分配，也就是在文件映射段找一块空闲内存分配出去。会在释放时直接归还系统，所以每次 mmap 都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大。这也是 malloc 只对大块内存使用 mmap  的原因

当这两种调用发生后，其实并没有真正分配内存。这些内存，都只在首次访问时才分配，也就是通过缺页异常进入内核中，再由内核来分配内存。应用程序用完内存后，还需要调用 free() 或 unmap() ，来释放这些不用的内存

用户空间的内存分配都是基于buddy算法（伙伴算法）。只有在内核空间，内核调用kmalloc去分配内存的时候，才会涉及到slab，Linux 则通过 slab 分配器来管理不到 1K小内存

系统也不会任由某个进程用完所有内存。在发现内存紧张时，系统就会通过一系列机制来回收内存

* 回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面
* 回收不常访问的内存：把不常用的内存通过交换分区直接写到磁盘中，Swap 其实就是把一块磁盘空间当成内存来用。它可以把进程暂时不用的数据存储到磁盘中（这个过程称为换出），当进程访问这些内存时，再从磁盘读取这些数据到内存中（这个过程称为换入）。通常只在内存不足时，才会发生 Swap 交换。并且由于磁盘读写的速度远比内存慢，Swap 会导致严重的内存性能问题
* 杀死进程：内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。一个进程消耗的内存越大，oom_score 就越大；一个进程运行占用的 CPU 越多，oom_score 就越小。进程的 oom_score 越大，代表消耗的内存越多，也就越容易被 OOM 杀死

```
// oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；其中 -17 表示禁止 OOM
// 把 sshd 进程的 oom_adj 调小为 -16，这样， sshd 进程就不容易被 OOM 杀死
echo -16 > /proc/$(pidof sshd)/oom_adj
```

##### 查看内存使用情况

free 显示整个系统的内存使用情况

```
// 注意不同版本的free输出可能会有所不同，默认以字节为单位
free
              total        used        free      shared  buff/cache   available
Mem:        8169348      263524     6875352         668     1030472     7611064
Swap:             0           0           0
```

* 第一列，total 是总内存大小
* 第二列，used 是已使用内存的大小，包含了共享内存
* 第三列，free 是未使用内存的大小
* 第四列，shared 是共享内存的大小
* 第五列，buff/cache 是缓存和缓冲区的大小
* 最后一列，available 是新进程可用内存的大小，不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大

可以用 top 或者 ps 等工具查看进程的内存使用情况

```
//  按下M切换到内存排序
top
...
KiB Mem :  8169348 total,  6871440 free,   267096 used,  1030812 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  7607492 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  430 root      19  -1  122360  35588  23748 S   0.0  0.4   0:32.17 systemd-journal
 1075 root      20   0  771860  22744  11368 S   0.0  0.3   0:38.89 snapd
 1048 root      20   0  170904  17292   9488 S   0.0  0.2   0:00.24 networkd-dispat
    1 root      20   0   78020   9156   6644 S   0.0  0.1   0:22.92 systemd
12376 azure     20   0   76632   7456   6420 S   0.0  0.1   0:00.01 systemd
12374 root      20   0  107984   7312   6304 S   0.0  0.1   0:00.00 sshd
...
```

* VIRT 是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内
* RES 是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括 Swap 和共享内存
* SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等
* %MEM 是进程使用物理内存占系统总内存的百分比

虚拟内存通常并不会全部分配物理内存。每个进程的虚拟内存都比常驻内存大得多。共享内存 SHR 并不一定是共享的，如程序的代码段、非共享的动态链接库，也都算在 SHR 里。SHR 也包括了进程间真正共享的内存

### 怎么理解内存中的Buffer和Cache？

磁盘和文件这两种读写方式所使用的缓存是不同的，也就是 Cache 和 Buffer 区别

* 磁盘：是一个块设备，可以划分为不同的分区；在分区之上再创建文件系统，挂载到某个目录，之后才可以在这个目录中读写文件。读写磁盘或者分区时，就会跳过文件系统，也就是所谓的“裸I/O“

* 文件：Linux 中“一切皆文件”，指的是所有类型的文件，一般而言则是普通文件。在读写普通文件时，会经过文件系统，由文件系统负责与磁盘交互

```
// 注意不同版本的free输出可能会有所不同
free
              total        used        free      shared  buff/cache   available
Mem:        8169348      263524     6875352         668     1030472     7611064
Swap:             0           0           0
```

##### free 数据的来源

* Buffers 是内核缓冲区用到的内存，对应的是  /proc/meminfo 中的 Buffers 值。是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等
* Cache 是内核页缓存和 Slab 用到的内存，对应的是  /proc/meminfo 中的 Cached 与 SReclaimable 之和。是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录

##### 案例分析

```
// 清理文件页、目录项、Inodes等各种缓存
$ echo 3 > /proc/sys/vm/drop_caches
```

磁盘和文件写的情况：

```
// 第一个终端每隔1秒输出1组数据
$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  0      0 7743608   1112  92168    0    0     0     0   52  152  0  1 100  0  0
0  0      0 7743608   1112  92168    0    0     0     0   36   92  0  0 100  0  0

buff 和 cache 就是free里面的 Buffers 和 Cache，单位是 KB
bi 和 bo 分别表示块设备读取和写入的大小，单位为块 / 秒。Linux 中块的大小是 1KB，所以这个单位也是 KB/s

// 通过读取随机设备，生成一个 500MB 大小的文件
$ dd if=/dev/urandom of=/tmp/file bs=1M count=500

// 观察第一个终端的情况
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  0      0 7499460   1344 230484    0    0     0     0   29  145  0  0 100  0  0
 1  0      0 7338088   1752 390512    0    0   488     0   39  558  0 47 53  0  0
 1  0      0 7158872   1752 568800    0    0     0     4   30  376  1 50 49  0  0
 1  0      0 6980308   1752 747860    0    0     0     0   24  360  0 50 50  0  0
 0  0      0 6977448   1752 752072    0    0     0     0   29  138  0  0 100  0  0
 0  0      0 6977440   1760 752080    0    0     0   152   42  212  0  1 99  1  0
...
 0  1      0 6977216   1768 752104    0    0     4 122880   33  234  0  1 51 49  0
 0  1      0 6977440   1768 752108    0    0     0 10240   38  196  0  0 50 50  0
 
Cache 在不停地增长，而 Buffer 基本保持不变
 
// 第二个终端继续运行dd命令向磁盘分区/dev/sdb1写入2G数据
// 首先清理缓存
$ echo 3 > /proc/sys/vm/drop_caches
$ dd if=/dev/urandom of=/dev/sdb1 bs=1M count=2048 

// 观察第一个终端的情况
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 7584780 153592  97436    0    0   684     0   31  423  1 48 50  2  0
 1  0      0 7418580 315384 101668    0    0     0     0   32  144  0 50 50  0  0
 1  0      0 7253664 475844 106208    0    0     0     0   20  137  0 50 50  0  0
 1  0      0 7093352 631800 110520    0    0     0     0   23  223  0 50 50  0  0
 1  1      0 6930056 790520 114980    0    0     0 12804   23  168  0 50 42  9  0
 1  0      0 6757204 949240 119396    0    0     0 183804   24  191  0 53 26 21  0
 1  1      0 6591516 1107960 123840    0    0     0 77316   22  232  0 52 16 33  0

写磁盘时（也就是 bo 大于  0 时），Buffer 和 Cache 都在增长，但显然 Buffer 的增长快得多
```

磁盘和文件读的情况：

```
// 第二个终端从文件 /tmp/file 中，读取数据写入空设备
// 首先清理缓存
$ echo 3 > /proc/sys/vm/drop_caches
$ dd if=/tmp/file of=/dev/null

// 观察第一个终端的情况
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  1      0 7724164   2380 110844    0    0 16576     0   62  360  2  2 76 21  0
 0  1      0 7691544   2380 143472    0    0 32640     0   46  439  1  3 50 46  0
 0  1      0 7658736   2380 176204    0    0 32640     0   54  407  1  4 50 46  0
 0  1      0 7626052   2380 208908    0    0 32640    40   44  422  2  2 50 46  0
 
 Buffer 保持不变，而 Cache 则在不停增长
 
// 从磁盘分区 /dev/sda1 中读取数据，写入空设备 
// 首先清理缓存
$ echo 3 > /proc/sys/vm/drop_caches
# 运行dd命令读取文件
$ dd if=/dev/sda1 of=/dev/null bs=1M count=1024

// 观察第一个终端的情况

procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 7225880   2716 608184    0    0     0     0   48  159  0  0 100  0  0
 0  1      0 7199420  28644 608228    0    0 25928     0   60  252  0  1 65 35  0
 0  1      0 7167092  60900 608312    0    0 32256     0   54  269  0  1 50 49  0
 0  1      0 7134416  93572 608376    0    0 32672     0   53  253  0  0 51 49  0
 0  1      0 7101484 126320 608480    0    0 32748     0   80  414  0  1 50 49  0
 
 Buffer 和 Cache 都在增长，但显然 Buffer 的增长快很多
```

Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中